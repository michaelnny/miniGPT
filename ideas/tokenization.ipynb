{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encodings specify how text is converted into tokens. Different models use different encodings.\n",
    "\n",
    "`tiktoken` supports three encodings used by OpenAI models:\n",
    "    \n",
    "| Encoding name           | OpenAI models                                       |\n",
    "|-------------------------|-----------------------------------------------------|\n",
    "| `cl100k_base`           | `gpt-4`, `gpt-3.5-turbo`, `text-embedding-ada-002`  |\n",
    "| `p50k_base`             | Codex models, `text-davinci-002`, `text-davinci-003`|\n",
    "| `r50k_base` (or `gpt2`) | GPT-3 models like `davinci`                         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt2', 'r50k_base', 'p50k_base', 'p50k_edit', 'cl100k_base']\n"
     ]
    }
   ],
   "source": [
    "encode_names = tiktoken.list_encoding_names()\n",
    "\n",
    "print(encode_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding name: gpt2, vocab size: 50257\n",
      "\n",
      "Encoding name: r50k_base, vocab size: 50257\n",
      "\n",
      "Encoding name: p50k_base, vocab size: 50281\n",
      "\n",
      "Encoding name: p50k_edit, vocab size: 50284\n",
      "\n",
      "Encoding name: cl100k_base, vocab size: 100277\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for encode_name in encode_names:\n",
    "    encoding = tiktoken.get_encoding(encode_name)\n",
    "    print(f'Encoding name: {encoding.name}, vocab size: {encoding.n_vocab}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or use tiktoken.encoding_for_model() to automatically load the correct encoding for a given model name\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.max_token_value + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<|endoftext|>'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.special_tokens_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.eot_token"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode some text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22017, 0, 383, 256, 1134, 30001, 318, 1049, 0]\n"
     ]
    }
   ],
   "source": [
    "encoded = encoding.encode(\"Wow! The tiktoken is great!\")\n",
    "print(encoded)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the encoded back into text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wow! The tiktoken is great!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.decode(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13681, 0]\n",
      "[18223, 0]\n"
     ]
    }
   ],
   "source": [
    "print(encoding.encode(\"Great!\"))\n",
    "print(encoding.encode(\"great!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1212, 318, 198, 257, 1049, 198, 198, 10827, 0]\n"
     ]
    }
   ],
   "source": [
    "print(encoding.encode(\"This is\\n a great\\n\\nnews!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[198, 198, 47]\n"
     ]
    }
   ],
   "source": [
    "print(encoding.encode(\"\\n\\nP\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\n'\n",
      "True\n",
      "'\\n\\n'\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for tk in [198, 628]:\n",
    "    print(repr(encoding.decode([tk])))\n",
    "    print(encoding.decode_single_token_bytes(tk) == b'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50281\n"
     ]
    }
   ],
   "source": [
    "enc_base = tiktoken.get_encoding(\"p50k_base\")\n",
    "max_token_value = enc_base.max_token_value + 1\n",
    "print(max_token_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<|PAD|>': 50282, '<|UNK|>': 50283, '<|CLS|>': 50284, '<|SEP|>': 50285, '<|MASK|>': 50286, '<|SOT|>': 50287, '<|EOT|>': 50288}\n"
     ]
    }
   ],
   "source": [
    "# add custom special tokens\n",
    "special_tokens_list = ['PAD', 'UNK', 'CLS', 'SEP', 'MASK', 'SOT', 'EOT']\n",
    "special_tokens = {}\n",
    "\n",
    "for i, tk in enumerate(special_tokens_list):\n",
    "    special_tokens[f\"<|{tk}|>\"] = max_token_value+(1+i)\n",
    "\n",
    "print(special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<|MASK|>', '<|endoftext|>', '<|EOT|>', '<|PAD|>', '<|CLS|>', '<|SOT|>', '<|UNK|>', '<|SEP|>'}\n",
      "50289\n"
     ]
    }
   ],
   "source": [
    "# In production, load the arguments directly instead of accessing private attributes\n",
    "# See openai_public.py for examples of arguments for specific encodings\n",
    "enc = tiktoken.Encoding(\n",
    "    # If you're changing the set of special tokens, make sure to use a different name\n",
    "    # It should be clear from the name what behaviour to expect.\n",
    "    name=\"p50k_custom\",\n",
    "    pat_str=enc_base._pat_str,\n",
    "    mergeable_ranks=enc_base._mergeable_ranks,\n",
    "    special_tokens={\n",
    "        **enc_base._special_tokens,\n",
    "        **special_tokens,\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "print(enc.special_tokens_set)\n",
    "print(enc.max_token_value + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_encodings(example_string: str) -> None:\n",
    "    \"\"\"Prints a comparison of three string encodings.\"\"\"\n",
    "    # print the example string\n",
    "    print(f'\\nExample string: \"{example_string}\"')\n",
    "    # for each encoding, print the # of tokens, the token integers, and the token bytes\n",
    "    for encoding_name in [\"gpt2\", \"p50k_base\", \"cl100k_base\"]:\n",
    "        encoding = tiktoken.get_encoding(encoding_name)\n",
    "        token_integers = encoding.encode(example_string)\n",
    "        num_tokens = len(token_integers)\n",
    "        token_bytes = [encoding.decode_single_token_bytes(token) for token in token_integers]\n",
    "        print()\n",
    "        print(f\"{encoding_name}: {num_tokens} tokens\")\n",
    "        print(f\"token integers: {token_integers}\")\n",
    "        print(f\"token bytes: {token_bytes}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example string: \"This is\n",
      "a great\n",
      "\n",
      "news!\"\n",
      "\n",
      "gpt2: 9 tokens\n",
      "token integers: [1212, 318, 198, 64, 1049, 198, 198, 10827, 0]\n",
      "token bytes: [b'This', b' is', b'\\n', b'a', b' great', b'\\n', b'\\n', b'news', b'!']\n",
      "\n",
      "p50k_base: 9 tokens\n",
      "token integers: [1212, 318, 198, 64, 1049, 198, 198, 10827, 0]\n",
      "token bytes: [b'This', b' is', b'\\n', b'a', b' great', b'\\n', b'\\n', b'news', b'!']\n",
      "\n",
      "cl100k_base: 8 tokens\n",
      "token integers: [2028, 374, 198, 64, 2294, 271, 10189, 0]\n",
      "token bytes: [b'This', b' is', b'\\n', b'a', b' great', b'\\n\\n', b'news', b'!']\n"
     ]
    }
   ],
   "source": [
    "compare_encodings(\"This is\\na great\\n\\nnews!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example string: \"So far everything is doing great!\"\n",
      "\n",
      "gpt2: 7 tokens\n",
      "token integers: [2396, 1290, 2279, 318, 1804, 1049, 0]\n",
      "token bytes: [b'So', b' far', b' everything', b' is', b' doing', b' great', b'!']\n",
      "\n",
      "p50k_base: 7 tokens\n",
      "token integers: [2396, 1290, 2279, 318, 1804, 1049, 0]\n",
      "token bytes: [b'So', b' far', b' everything', b' is', b' doing', b' great', b'!']\n",
      "\n",
      "cl100k_base: 7 tokens\n",
      "token integers: [4516, 3117, 4395, 374, 3815, 2294, 0]\n",
      "token bytes: [b'So', b' far', b' everything', b' is', b' doing', b' great', b'!']\n"
     ]
    }
   ],
   "source": [
    "compare_encodings(\"So far everything is doing great!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example string: \"你好吗？\"\n",
      "\n",
      "gpt2: 9 tokens\n",
      "token integers: [19526, 254, 25001, 121, 28938, 245, 171, 120, 253]\n",
      "token bytes: [b'\\xe4\\xbd', b'\\xa0', b'\\xe5\\xa5', b'\\xbd', b'\\xe5\\x90', b'\\x97', b'\\xef', b'\\xbc', b'\\x9f']\n",
      "\n",
      "p50k_base: 9 tokens\n",
      "token integers: [19526, 254, 25001, 121, 28938, 245, 171, 120, 253]\n",
      "token bytes: [b'\\xe4\\xbd', b'\\xa0', b'\\xe5\\xa5', b'\\xbd', b'\\xe5\\x90', b'\\x97', b'\\xef', b'\\xbc', b'\\x9f']\n",
      "\n",
      "cl100k_base: 5 tokens\n",
      "token integers: [57668, 53901, 7305, 245, 11571]\n",
      "token bytes: [b'\\xe4\\xbd\\xa0', b'\\xe5\\xa5\\xbd', b'\\xe5\\x90', b'\\x97', b'\\xef\\xbc\\x9f']\n"
     ]
    }
   ],
   "source": [
    "compare_encodings(\"你好吗？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example string: \"2 + 2 = 4\"\n",
      "\n",
      "gpt2: 5 tokens\n",
      "token integers: [17, 1343, 362, 796, 604]\n",
      "token bytes: [b'2', b' +', b' 2', b' =', b' 4']\n",
      "\n",
      "p50k_base: 5 tokens\n",
      "token integers: [17, 1343, 362, 796, 604]\n",
      "token bytes: [b'2', b' +', b' 2', b' =', b' 4']\n",
      "\n",
      "cl100k_base: 7 tokens\n",
      "token integers: [17, 489, 220, 17, 284, 220, 19]\n",
      "token bytes: [b'2', b' +', b' ', b'2', b' =', b' ', b'4']\n"
     ]
    }
   ],
   "source": [
    "compare_encodings(\"2 + 2 = 4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
